{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kubernetes Operators \u00b6 Kubernetes Operators is a series of labs about deploying applications to Kubernetes using the Extensions API to create Custom Resources (CR) and customize controllers using the Operator Pattern. This workshop uses the Operator Framework to create operators. Pre-requirements \u00b6 a Free IBM Cloud account, to create a new IBM Cloud account, follow the instructions here . a Red Hat OpenShift Kubernetes Service (ROKS) v4.5 using a cluster with admin rights, CognitiveLabs.ai account, to access a client terminal at CognitiveLabs.ai, follow the instructions here . Labs \u00b6 Setup , Lab 1 Create a Custom Resource (CR) , Lab2 Create an Operator of Type Go using the Operator SDK , Lab3 Create an Operator using an Existing Helm Chart , Tools Technologies \u00b6 Red Hat OpenShift Kubernetes Service (ROKS) v4.5 Operator Framework Contributors \u00b6 Rojan Jose, rojanjose Remko de Knikker, remkohdev","title":"About the workshop"},{"location":"#kubernetes-operators","text":"Kubernetes Operators is a series of labs about deploying applications to Kubernetes using the Extensions API to create Custom Resources (CR) and customize controllers using the Operator Pattern. This workshop uses the Operator Framework to create operators.","title":"Kubernetes Operators"},{"location":"#pre-requirements","text":"a Free IBM Cloud account, to create a new IBM Cloud account, follow the instructions here . a Red Hat OpenShift Kubernetes Service (ROKS) v4.5 using a cluster with admin rights, CognitiveLabs.ai account, to access a client terminal at CognitiveLabs.ai, follow the instructions here .","title":"Pre-requirements"},{"location":"#labs","text":"Setup , Lab 1 Create a Custom Resource (CR) , Lab2 Create an Operator of Type Go using the Operator SDK , Lab3 Create an Operator using an Existing Helm Chart , Tools","title":"Labs"},{"location":"#technologies","text":"Red Hat OpenShift Kubernetes Service (ROKS) v4.5 Operator Framework","title":"Technologies"},{"location":"#contributors","text":"Rojan Jose, rojanjose Remko de Knikker, remkohdev","title":"Contributors"},{"location":"lab1/","text":"Create a Custom Resource \u00b6 Create a Custom Resource Operators Ready Made Operators Create a Custom Resource and Operator using the Operator SDK Install sdk-operator Create the Operator Cleanup Application CRD Create a Custom Resource (CR) \u00b6 https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/ Custom Resource Definitions (CRD) were added in Kubernetes v1.7 in June 2017. A CRD defines Custom Resources (CR). A CR is an extension of the Kubernetes API that allows you to store your own API Objects and lets the API Server handle the lifecycle of a CR. On their own, CRs simply let you store and retrieve structured data. For instance, our Guestbook application consists of an object Guestbook with attributes GuestbookTitle and GuestbookSubtitle , and a Guestbook handles objectes of type GuestbookMessage with attributes Message , Sender . You have to ask yourself if it makes sense if your objects are added as a Custom Resource to Kubernetes or not. If your API is a Declarative API you can consider adding a CR. Your API has a small number of small objects (resources). The objects define configuration of applications or infrastructure. The objects are updated relatively infrequently. Users often need to read and write the objects. main operations on the objects are CRUD (create, read, update and delete). Transactions between objects are not required. It doesn't immediately make sense to store messages by Guestbook users in Kubernetes, but it might make sense to store meta-data about a Guestbook deployment, for instance the title and subtitle of a Guestbook deployment, assigned resources or replicas. Another benefit of adding a Custom Resource is to view your types in the Kubernetes Dashboard. If you want to deploy a Guestbook instance as a Kubernetes API object and let the Kubernetes API Server handle the lifecycle events of the Guestbook deployment, you can create a Custom Resource Definition (CRD) for the Guestbook object as follows. That way you can deploy multiple Guestbooks with different titles and let each be managed by Kubernetes. cat <<EOF >>guestbook-crd.yaml apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: guestbooks.apps.ibm.com spec: group: apps.ibm.com versions: - name: v1 served: true storage: true schema: openAPIV3Schema: type: object properties: spec: type: object properties: guestbookTitle: type: string guestbookSubtitle: type: string scope: Namespaced names: plural: guestbooks singular: guestbook kind: Guestbook shortNames: - gb EOF You can see that the apiVersion is part of the apiextensions.k8s.io/v1 API Group in Kubernetes, which is the API that enables extensions, and the kind is set to CustomResourceDefinition . The served flag can disable and enable a version. Only 1 version can be flagged as the storage version. The spec.names.kind is used by your resource manifests and should be CamelCased. Create the Custom Resource for the Guestbook witht he command, oc create -f guestbook-crd.yaml When run in the terminal, $ oc create -f guestbook-crd.yaml customresourcedefinition.apiextensions.k8s.io/guestbooks.apps.ibm.com created You have now added a CR to the Kubernetes API, but you have not yet created a deployment of type Guestbook yet. Create a resource specification of type Guestbook named my-guestbook , cat <<EOF >>my-guestbook.yaml apiVersion: \"apps.ibm.com/v1\" kind: Guestbook metadata: name: my-guestbook spec: guestbookTitle: \"The Chemical Wedding of Remko\" guestbookSubtitle: \"First Day of Many\" EOF And to create the my-guestbook resource, run the command oc create -f my-guestbook.yaml When run in the terminal, $ oc create -f my-guestbook.yaml guestbook.apps.ibm.com/my-guestbook created If you list all Kubernetes resources, only the default Kubernetes service is listed. To list your Custom Resources, add the extended type to your command. $ oc get all NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE service/kubernetes ClusterIP 172 .21.0.1 <none> 443 /TCP 5d14h service/openshift ExternalName <none> kubernetes.default.svc.cluster.local <none> 5d14h service/openshift-apiserver ClusterIP 172 .21.6.8 <none> = 443 /TCP 5d14h $ oc get guestbook NAME AGE my-guestbook 8m32s To read the details for the my-guestbook of type Guestbook , describe the instance, $ oc describe guestbook my-guestbook Name: my-guestbook Namespace: default Labels: <none> Annotations: <none> API Version: apps.ibm.com/v1 Kind: Guestbook Metadata: Creation Timestamp: 2020 -06-30T20:31:36Z Generation: 1 Resource Version: 1081471 Self Link: /apis/apps.ibm.com/v1/namespaces/default/guestbooks/my-guestbook UID: dcbdcafc-999d-4051-9244-0315093357e7 Spec: Guestbook Subtitle: First Day of Many Guestbook Title: The Chemical Wedding of Remko Events: <none> Or retrieve the resource information by specifying the type, $ oc get Guestbook -o yaml apiVersion: v1 items: - apiVersion: apps.ibm.com/v1 kind: Guestbook metadata: creationTimestamp: \"2020-07-02T04:41:57Z\" generation: 1 name: my-guestbook namespace: default resourceVersion: \"1903244\" selfLink: /apis/apps.ibm.com/v1/namespaces/default/guestbooks/my-guestbook uid: 3f774899-3070-4e00-b74c-a6a14654faeb spec: guestbookSubtitle: First Day of Many guestbookTitle: The Chemical Wedding of Remko kind: List metadata: resourceVersion: \"\" selfLink: \"\" In the OpenShift web console, you can browse to Administration > Custom Resource Definitions and find the Guestbook CRD at /k8s/cluster/customresourcedefinitions/guestbooks.apps.ibm.com . You have now created a new type or Custom Resource (CR) and created an instance of your new type. But just having a new type and a new instance of the type, does not add as much control over the instances yet, we can basically only create and delete a static type with some descriptive meta-data. With a custom controller or Operator you can over-write the methods that are triggered at certain lifecycle events.","title":"Custom Resource (CR)"},{"location":"lab1/#create-a-custom-resource","text":"Create a Custom Resource Operators Ready Made Operators Create a Custom Resource and Operator using the Operator SDK Install sdk-operator Create the Operator Cleanup Application CRD","title":"Create a Custom Resource"},{"location":"lab1/#create-a-custom-resource-cr","text":"https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/ Custom Resource Definitions (CRD) were added in Kubernetes v1.7 in June 2017. A CRD defines Custom Resources (CR). A CR is an extension of the Kubernetes API that allows you to store your own API Objects and lets the API Server handle the lifecycle of a CR. On their own, CRs simply let you store and retrieve structured data. For instance, our Guestbook application consists of an object Guestbook with attributes GuestbookTitle and GuestbookSubtitle , and a Guestbook handles objectes of type GuestbookMessage with attributes Message , Sender . You have to ask yourself if it makes sense if your objects are added as a Custom Resource to Kubernetes or not. If your API is a Declarative API you can consider adding a CR. Your API has a small number of small objects (resources). The objects define configuration of applications or infrastructure. The objects are updated relatively infrequently. Users often need to read and write the objects. main operations on the objects are CRUD (create, read, update and delete). Transactions between objects are not required. It doesn't immediately make sense to store messages by Guestbook users in Kubernetes, but it might make sense to store meta-data about a Guestbook deployment, for instance the title and subtitle of a Guestbook deployment, assigned resources or replicas. Another benefit of adding a Custom Resource is to view your types in the Kubernetes Dashboard. If you want to deploy a Guestbook instance as a Kubernetes API object and let the Kubernetes API Server handle the lifecycle events of the Guestbook deployment, you can create a Custom Resource Definition (CRD) for the Guestbook object as follows. That way you can deploy multiple Guestbooks with different titles and let each be managed by Kubernetes. cat <<EOF >>guestbook-crd.yaml apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: guestbooks.apps.ibm.com spec: group: apps.ibm.com versions: - name: v1 served: true storage: true schema: openAPIV3Schema: type: object properties: spec: type: object properties: guestbookTitle: type: string guestbookSubtitle: type: string scope: Namespaced names: plural: guestbooks singular: guestbook kind: Guestbook shortNames: - gb EOF You can see that the apiVersion is part of the apiextensions.k8s.io/v1 API Group in Kubernetes, which is the API that enables extensions, and the kind is set to CustomResourceDefinition . The served flag can disable and enable a version. Only 1 version can be flagged as the storage version. The spec.names.kind is used by your resource manifests and should be CamelCased. Create the Custom Resource for the Guestbook witht he command, oc create -f guestbook-crd.yaml When run in the terminal, $ oc create -f guestbook-crd.yaml customresourcedefinition.apiextensions.k8s.io/guestbooks.apps.ibm.com created You have now added a CR to the Kubernetes API, but you have not yet created a deployment of type Guestbook yet. Create a resource specification of type Guestbook named my-guestbook , cat <<EOF >>my-guestbook.yaml apiVersion: \"apps.ibm.com/v1\" kind: Guestbook metadata: name: my-guestbook spec: guestbookTitle: \"The Chemical Wedding of Remko\" guestbookSubtitle: \"First Day of Many\" EOF And to create the my-guestbook resource, run the command oc create -f my-guestbook.yaml When run in the terminal, $ oc create -f my-guestbook.yaml guestbook.apps.ibm.com/my-guestbook created If you list all Kubernetes resources, only the default Kubernetes service is listed. To list your Custom Resources, add the extended type to your command. $ oc get all NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE service/kubernetes ClusterIP 172 .21.0.1 <none> 443 /TCP 5d14h service/openshift ExternalName <none> kubernetes.default.svc.cluster.local <none> 5d14h service/openshift-apiserver ClusterIP 172 .21.6.8 <none> = 443 /TCP 5d14h $ oc get guestbook NAME AGE my-guestbook 8m32s To read the details for the my-guestbook of type Guestbook , describe the instance, $ oc describe guestbook my-guestbook Name: my-guestbook Namespace: default Labels: <none> Annotations: <none> API Version: apps.ibm.com/v1 Kind: Guestbook Metadata: Creation Timestamp: 2020 -06-30T20:31:36Z Generation: 1 Resource Version: 1081471 Self Link: /apis/apps.ibm.com/v1/namespaces/default/guestbooks/my-guestbook UID: dcbdcafc-999d-4051-9244-0315093357e7 Spec: Guestbook Subtitle: First Day of Many Guestbook Title: The Chemical Wedding of Remko Events: <none> Or retrieve the resource information by specifying the type, $ oc get Guestbook -o yaml apiVersion: v1 items: - apiVersion: apps.ibm.com/v1 kind: Guestbook metadata: creationTimestamp: \"2020-07-02T04:41:57Z\" generation: 1 name: my-guestbook namespace: default resourceVersion: \"1903244\" selfLink: /apis/apps.ibm.com/v1/namespaces/default/guestbooks/my-guestbook uid: 3f774899-3070-4e00-b74c-a6a14654faeb spec: guestbookSubtitle: First Day of Many guestbookTitle: The Chemical Wedding of Remko kind: List metadata: resourceVersion: \"\" selfLink: \"\" In the OpenShift web console, you can browse to Administration > Custom Resource Definitions and find the Guestbook CRD at /k8s/cluster/customresourcedefinitions/guestbooks.apps.ibm.com . You have now created a new type or Custom Resource (CR) and created an instance of your new type. But just having a new type and a new instance of the type, does not add as much control over the instances yet, we can basically only create and delete a static type with some descriptive meta-data. With a custom controller or Operator you can over-write the methods that are triggered at certain lifecycle events.","title":"Create a Custom Resource (CR)"},{"location":"lab2/","text":"Create an Operator of Type Go using the Operator SDK \u00b6 About Operators \u00b6 See https://kubernetes.io/docs/concepts/extend-kubernetes/operator/ . Operators are clients of the Kubernetes API that act as controllers for a Custom Resource. Operators are extensions to Kubernetes that use custom resources to manage applications and their components. They follow the Kubernetes principle of the control loop. About the Operator Framework \u00b6 The Operator Framework is an open source toolkit to manage Operators. The Operator SDK provides the following workflow to develop a new Operator: The following workflow is for a new Go operator: Create a new operator project using the SDK Command Line Interface(CLI) Define new resource APIs by adding Custom Resource Definitions(CRD) Define Controllers to watch and reconcile resources Write the reconciling logic for your Controller using the SDK and controller-runtime APIs Use the SDK CLI to build and generate the operator deployment manifests Install sdk-operator \u00b6 For detailed installation instructions go here . To install the Operator SDK in Ubuntu, you need to install the Go tools and the Operator SDK. curl -LO https://golang.org/dl/go1.14.4.linux-amd64.tar.gz tar -C /usr/local -xzf go1.14.4.linux-amd64.tar.gz export PATH = $PATH :/usr/local/go/bin curl -LO https://github.com/operator-framework/operator-sdk/releases/download/v0.18.2/operator-sdk-v0.18.2-x86_64-linux-gnu chmod +x operator-sdk-v0.18.2-x86_64-linux-gnu sudo mkdir -p /usr/local/bin/ sudo cp operator-sdk-v0.18.2-x86_64-linux-gnu /usr/local/bin/operator-sdk rm operator-sdk-v0.18.2-x86_64-linux-gnu go version operator-sdk version 1. Create a New Project \u00b6 Create a new Operator project, export DOCKER_USERNAME = <your-docker-username> export OPERATOR_NAME = guestbook-operator export OPERATOR_PROJECT = guestbook-project export OPERATOR_GROUP = guestbook.remkoh.dev export OPERATOR_VERSION = v1 export CRD_KIND = Guestbook go version operator-sdk version operator-sdk new $OPERATOR_PROJECT --type go --repo github.com/ $DOCKER_USERNAME / $OPERATOR_NAME cd $OPERATOR_PROJECT The scaffolding of a new project will create an operator, an api and a controller. 2. Create a new API \u00b6 Add a new API definition for a new Custom Resource under pkg/apis and generate the Custom Resource Definition (CRD) and Custom Resource (CR) files under deploy/crds . operator-sdk add api --api-version = $OPERATOR_GROUP / $OPERATOR_VERSION --kind = $CRD_KIND The command will create a new API, a Custom Resource (CR), a Custom Resource Definition (CRD). One file is created in pkg/apis called addtoscheme_guestbook_v1.go that registers the new schema. One new file is created in pkg/apis/guestbook called group.go that defines the package. Four new files are created in pkg/apis/guestbook/v1 : doc.go, guestbook_types.go, register.go, zz_generated.deepcopy.go. The guestbook_types.go file, package v1 import ( metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" ) // GuestbookSpec defines the desired state of Guestbook type GuestbookSpec struct { } // GuestbookStatus defines the observed state of Guestbook type GuestbookStatus struct { } type Guestbook struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` Spec GuestbookSpec `json:\"spec,omitempty\"` Status GuestbookStatus `json:\"status,omitempty\"` } // GuestbookList contains a list of Guestbook type GuestbookList struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ListMeta `json:\"metadata,omitempty\"` Items [] Guestbook `json:\"items\"` } func init () { SchemeBuilder . Register ( & Guestbook {}, & GuestbookList {}) } The Custom Resource (CR) in file deploy/crds/guestbook.remkoh.dev_v1_guestbook_cr , apiVersion : guestbook.remkoh.dev/v1 kind : Guestbook metadata : name : example-guestbook spec : # Add fields here size : 3 The Custom Resource Definition (CRD) in file deploy/crds/guestbook.remkoh.dev_guestbooks_crd.yaml , apiVersion : apiextensions.k8s.io/v1 kind : CustomResourceDefinition metadata : name : guestbooks.guestbook.remkoh.dev spec : group : guestbook.remkoh.dev names : kind : Guestbook listKind : GuestbookList plural : guestbooks singular : guestbook scope : Namespaced versions : - name : v1 schema : openAPIV3Schema : description : Guestbook is the Schema for the guestbooks API properties : apiVersion : description : 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources' type : string kind : description : 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds' type : string metadata : type : object spec : description : GuestbookSpec defines the desired state of Guestbook type : object status : description : GuestbookStatus defines the observed state of Guestbook type : object type : object served : true storage : true subresources : status : {} 3. Create a new Controller \u00b6 Add a new controller under pkg/controller/<kind> . operator-sdk add controller --api-version = $OPERATOR_GROUP / $OPERATOR_VERSION --kind = $CRD_KIND This command creates two files in pkg/controller : add_guestbook.go , which registers the new controller, and guestbook/guestbook_controller.go , which is the actual custom controller logic. The file guestbook/guestbook_controller.go defines the Reconcile function, // Reconcile reads state of the cluster for a Guestbook object and makes changes based on the state read and what is in the Guestbook.Spec // TODO(user): User must modify this Reconcile function to implement their own Controller logic. This example creates a Pod as an example func ( r * ReconcileGuestbook ) Reconcile ( request reconcile . Request ) ( reconcile . Result , error ) { ... // Fetch the Guestbook instance instance := & guestbookv1 . Guestbook {} ... // Define a new Pod object pod := newPodForCR ( instance ) ... } 4. Compile and Build the Code \u00b6 The operator-sdk build command compiles the code and builds the executables. fter you built the image, push it to your image registry, e.g. Docker hub. operator-sdk build docker.io/ $DOCKER_USERNAME / $OPERATOR_NAME docker login docker.io -u $DOCKER_USERNAME docker push docker.io/ $DOCKER_USERNAME / $OPERATOR_NAME 5. Deploy the Operator \u00b6 First replace the image attribute in the operator resource with the built image, sed -i \"s|REPLACE_IMAGE|docker.io/ $DOCKER_USERNAME / $OPERATOR_NAME |g\" deploy/operator.yaml Make sure you are connected to the OpenShift cluster (see above how to connect), and deploy the operator with the following template code. oc create sa $OPERATOR_PROJECT oc create -f deploy/role.yaml oc create -f deploy/role_binding.yaml oc create -f deploy/crds/ ${ OPERATOR_GROUP } _ ${ CRD_KIND ,, } s_crd.yaml oc create -f deploy/operator.yaml oc create -f deploy/crds/ ${ OPERATOR_GROUP } _ ${ OPERATOR_VERSION } _ ${ CRD_KIND ,, } _cr.yaml oc get deployment $OPERATOR_PROJECT oc get pod -l app = example- ${ CRD_KIND ,, } oc describe ${ CRD_KIND ,, } s. ${ OPERATOR_GROUP } example- ${ CRD_KIND ,, } For our example Guestbook project the above templates should resolve as follows, oc create sa guestbook-project oc create -f deploy/role.yaml oc create -f deploy/role_binding.yaml oc create -f deploy/crds/guestbook.remkoh.dev_guestbooks_crd.yaml oc create -f deploy/operator.yaml oc create -f deploy/crds/guestbook.remkoh.dev_v1_guestbook_cr.yaml oc get deployment guestbook-project oc get pod -l app = example-guestbook oc describe guestbooks.guestbook.remkoh.dev example-guestbook Cleanup \u00b6 oc delete sa $OPERATOR_PROJECT oc delete role $OPERATOR_PROJECT oc delete rolebinding $OPERATOR_PROJECT oc delete customresourcedefinition ${ CRD_KIND ,, } s. ${ OPERATOR_GROUP } oc delete deployment $OPERATOR_PROJECT","title":"Go Operator with Operator SDK"},{"location":"lab2/#create-an-operator-of-type-go-using-the-operator-sdk","text":"","title":"Create an Operator of Type Go using the Operator SDK"},{"location":"lab2/#about-operators","text":"See https://kubernetes.io/docs/concepts/extend-kubernetes/operator/ . Operators are clients of the Kubernetes API that act as controllers for a Custom Resource. Operators are extensions to Kubernetes that use custom resources to manage applications and their components. They follow the Kubernetes principle of the control loop.","title":"About Operators"},{"location":"lab2/#about-the-operator-framework","text":"The Operator Framework is an open source toolkit to manage Operators. The Operator SDK provides the following workflow to develop a new Operator: The following workflow is for a new Go operator: Create a new operator project using the SDK Command Line Interface(CLI) Define new resource APIs by adding Custom Resource Definitions(CRD) Define Controllers to watch and reconcile resources Write the reconciling logic for your Controller using the SDK and controller-runtime APIs Use the SDK CLI to build and generate the operator deployment manifests","title":"About the Operator Framework"},{"location":"lab2/#install-sdk-operator","text":"For detailed installation instructions go here . To install the Operator SDK in Ubuntu, you need to install the Go tools and the Operator SDK. curl -LO https://golang.org/dl/go1.14.4.linux-amd64.tar.gz tar -C /usr/local -xzf go1.14.4.linux-amd64.tar.gz export PATH = $PATH :/usr/local/go/bin curl -LO https://github.com/operator-framework/operator-sdk/releases/download/v0.18.2/operator-sdk-v0.18.2-x86_64-linux-gnu chmod +x operator-sdk-v0.18.2-x86_64-linux-gnu sudo mkdir -p /usr/local/bin/ sudo cp operator-sdk-v0.18.2-x86_64-linux-gnu /usr/local/bin/operator-sdk rm operator-sdk-v0.18.2-x86_64-linux-gnu go version operator-sdk version","title":"Install sdk-operator"},{"location":"lab2/#1-create-a-new-project","text":"Create a new Operator project, export DOCKER_USERNAME = <your-docker-username> export OPERATOR_NAME = guestbook-operator export OPERATOR_PROJECT = guestbook-project export OPERATOR_GROUP = guestbook.remkoh.dev export OPERATOR_VERSION = v1 export CRD_KIND = Guestbook go version operator-sdk version operator-sdk new $OPERATOR_PROJECT --type go --repo github.com/ $DOCKER_USERNAME / $OPERATOR_NAME cd $OPERATOR_PROJECT The scaffolding of a new project will create an operator, an api and a controller.","title":"1. Create a New Project"},{"location":"lab2/#2-create-a-new-api","text":"Add a new API definition for a new Custom Resource under pkg/apis and generate the Custom Resource Definition (CRD) and Custom Resource (CR) files under deploy/crds . operator-sdk add api --api-version = $OPERATOR_GROUP / $OPERATOR_VERSION --kind = $CRD_KIND The command will create a new API, a Custom Resource (CR), a Custom Resource Definition (CRD). One file is created in pkg/apis called addtoscheme_guestbook_v1.go that registers the new schema. One new file is created in pkg/apis/guestbook called group.go that defines the package. Four new files are created in pkg/apis/guestbook/v1 : doc.go, guestbook_types.go, register.go, zz_generated.deepcopy.go. The guestbook_types.go file, package v1 import ( metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" ) // GuestbookSpec defines the desired state of Guestbook type GuestbookSpec struct { } // GuestbookStatus defines the observed state of Guestbook type GuestbookStatus struct { } type Guestbook struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ObjectMeta `json:\"metadata,omitempty\"` Spec GuestbookSpec `json:\"spec,omitempty\"` Status GuestbookStatus `json:\"status,omitempty\"` } // GuestbookList contains a list of Guestbook type GuestbookList struct { metav1 . TypeMeta `json:\",inline\"` metav1 . ListMeta `json:\"metadata,omitempty\"` Items [] Guestbook `json:\"items\"` } func init () { SchemeBuilder . Register ( & Guestbook {}, & GuestbookList {}) } The Custom Resource (CR) in file deploy/crds/guestbook.remkoh.dev_v1_guestbook_cr , apiVersion : guestbook.remkoh.dev/v1 kind : Guestbook metadata : name : example-guestbook spec : # Add fields here size : 3 The Custom Resource Definition (CRD) in file deploy/crds/guestbook.remkoh.dev_guestbooks_crd.yaml , apiVersion : apiextensions.k8s.io/v1 kind : CustomResourceDefinition metadata : name : guestbooks.guestbook.remkoh.dev spec : group : guestbook.remkoh.dev names : kind : Guestbook listKind : GuestbookList plural : guestbooks singular : guestbook scope : Namespaced versions : - name : v1 schema : openAPIV3Schema : description : Guestbook is the Schema for the guestbooks API properties : apiVersion : description : 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources' type : string kind : description : 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds' type : string metadata : type : object spec : description : GuestbookSpec defines the desired state of Guestbook type : object status : description : GuestbookStatus defines the observed state of Guestbook type : object type : object served : true storage : true subresources : status : {}","title":"2. Create a new API"},{"location":"lab2/#3-create-a-new-controller","text":"Add a new controller under pkg/controller/<kind> . operator-sdk add controller --api-version = $OPERATOR_GROUP / $OPERATOR_VERSION --kind = $CRD_KIND This command creates two files in pkg/controller : add_guestbook.go , which registers the new controller, and guestbook/guestbook_controller.go , which is the actual custom controller logic. The file guestbook/guestbook_controller.go defines the Reconcile function, // Reconcile reads state of the cluster for a Guestbook object and makes changes based on the state read and what is in the Guestbook.Spec // TODO(user): User must modify this Reconcile function to implement their own Controller logic. This example creates a Pod as an example func ( r * ReconcileGuestbook ) Reconcile ( request reconcile . Request ) ( reconcile . Result , error ) { ... // Fetch the Guestbook instance instance := & guestbookv1 . Guestbook {} ... // Define a new Pod object pod := newPodForCR ( instance ) ... }","title":"3. Create a new Controller"},{"location":"lab2/#4-compile-and-build-the-code","text":"The operator-sdk build command compiles the code and builds the executables. fter you built the image, push it to your image registry, e.g. Docker hub. operator-sdk build docker.io/ $DOCKER_USERNAME / $OPERATOR_NAME docker login docker.io -u $DOCKER_USERNAME docker push docker.io/ $DOCKER_USERNAME / $OPERATOR_NAME","title":"4. Compile and Build the Code"},{"location":"lab2/#5-deploy-the-operator","text":"First replace the image attribute in the operator resource with the built image, sed -i \"s|REPLACE_IMAGE|docker.io/ $DOCKER_USERNAME / $OPERATOR_NAME |g\" deploy/operator.yaml Make sure you are connected to the OpenShift cluster (see above how to connect), and deploy the operator with the following template code. oc create sa $OPERATOR_PROJECT oc create -f deploy/role.yaml oc create -f deploy/role_binding.yaml oc create -f deploy/crds/ ${ OPERATOR_GROUP } _ ${ CRD_KIND ,, } s_crd.yaml oc create -f deploy/operator.yaml oc create -f deploy/crds/ ${ OPERATOR_GROUP } _ ${ OPERATOR_VERSION } _ ${ CRD_KIND ,, } _cr.yaml oc get deployment $OPERATOR_PROJECT oc get pod -l app = example- ${ CRD_KIND ,, } oc describe ${ CRD_KIND ,, } s. ${ OPERATOR_GROUP } example- ${ CRD_KIND ,, } For our example Guestbook project the above templates should resolve as follows, oc create sa guestbook-project oc create -f deploy/role.yaml oc create -f deploy/role_binding.yaml oc create -f deploy/crds/guestbook.remkoh.dev_guestbooks_crd.yaml oc create -f deploy/operator.yaml oc create -f deploy/crds/guestbook.remkoh.dev_v1_guestbook_cr.yaml oc get deployment guestbook-project oc get pod -l app = example-guestbook oc describe guestbooks.guestbook.remkoh.dev example-guestbook","title":"5. Deploy the Operator"},{"location":"lab2/#cleanup","text":"oc delete sa $OPERATOR_PROJECT oc delete role $OPERATOR_PROJECT oc delete rolebinding $OPERATOR_PROJECT oc delete customresourcedefinition ${ CRD_KIND ,, } s. ${ OPERATOR_GROUP } oc delete deployment $OPERATOR_PROJECT","title":"Cleanup"},{"location":"lab3-v0.19/","text":"Create an Operator using an Existing Helm Chart \u00b6 The Operator Framework is an open source project that provides developer and runtime Kubernetes tools, enabling you to accelerate the development of an Operator. The Operator SDK provides the tools to build, test and package Operators. The following workflow is for a Helm operator using existing chart : Create a new operator project using the SDK Command Line Interface(CLI) Create a new (or add your existing) Helm chart for use by the operator\u2019s reconciling logic Use the SDK CLI to build and generate the operator deployment manifests Optionally add additional CRD\u2019s using the SDK CLI and repeat steps 2 and 3 Use the SDK bundle feature to package the operator for OLM deployment. Deploy, test and publish. In this lab, we will use the IBM Guestbook helm chart available here as the base to scaffold a new operator. Information of creating a new operator can be found here Setup \u00b6 The lab requires you to have the operator-sdk installed. Login into the client CLI following these instructions . Run the command shown below to install the prerequisites: source < ( curl -s https://raw.githubusercontent.com/rojanjose/guestbook-helm-operator/master/scripts/operatorInstall.sh ) Check the command output to ensure the SDK version is correct. ... Checking prereqs version ... Go version: go version go1.14.4 linux/amd64 ----------------------------- Helm version: version.BuildInfo { Version: \"v3.0.3\" , GitCommit: \"ac925eb7279f4a6955df663a0128044a8a6b7593\" , GitTreeState: \"clean\" , GoVersion: \"go1.13.6\" } ----------------------------- Operator-sdk version: operator-sdk version: \"v0.19.2\" , commit: \"4282ce9acdef6d7a1e9f90832db4dc5a212ae850\" , kubernetes version: \"v1.18.2\" , go version: \"go1.13.10 linux/amd64\" Log into your OpenShift cluster . oc login --token = YQ2-mTJIWlz1gsWeI2tsO4CzHBbRSCQbH-IdA3tEFrM --server = https://c100-e.us-east.containers.cloud.ibm.com:32055 Create the operator \u00b6 1. Create a new project \u00b6 Export these environment variables prior to starting the project. export DOCKER_USERNAME = <your-docker-username> export OPERATOR_NAME = guestbook-operator export OPERATOR_PROJECT = guestbook-operator-project export OPERATOR_VERSION = v1.0.0 export IMG = docker.io/ ${ DOCKER_USERNAME } / ${ OPERATOR_NAME } : ${ OPERATOR_VERSION } Create a new project called guestbook-operator using the existing guestbook helm chart. The guestbook chart is available at the repo https://ibm.github.io/helm101/ . operator-sdk new $OPERATOR_PROJECT --type = helm --helm-chart = guestbook --helm-chart-repo = https://ibm.github.io/helm101/ cd $OPERATOR_PROJECT Output: INFO [ 0000 ] Creating new Helm operator 'guestbook-operator-project' . INFO [ 0000 ] Created helm-charts/guestbook INFO [ 0000 ] Generating RBAC rules I0813 23 :07:00.995286 11211 request.go:621 ] Throttling request took 1 .031369076s, request: GET:https://c100-e.us-east.containers.cloud.ibm.com:31941/apis/scheduling.k8s.io/v1?timeout = 32s WARN [ 0002 ] The RBAC rules generated in deploy/role.yaml are based on the chart 's default manifest. Some rules may be missing for resources that are only enabled with custom values, and some existing rules may be overly broad. Double check the rules generated in deploy/role.yaml to ensure they meet the operator' s permission requirements. INFO [ 0002 ] Created build/Dockerfile INFO [ 0002 ] Created deploy/service_account.yaml INFO [ 0002 ] Created deploy/role.yaml INFO [ 0002 ] Created deploy/role_binding.yaml INFO [ 0002 ] Created deploy/operator.yaml INFO [ 0002 ] Created deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml INFO [ 0002 ] Generated CustomResourceDefinition manifests. INFO [ 0002 ] Project creation complete. Review the code and customize the operator logic as required to obtain the desired results. By default, the Guestbook operator installs the configured helm chart watches the events shown in the watches.yaml . - group : helm.operator-sdk version : v1alpha1 kind : Guestbook chart : helm-charts/guestbook The custom resource (CR) file defines the properties used by operator while it creates an instance of the Guestbook application. These properties are derived from the values.yaml file in the Helm chart. apiVersion : helm.operator-sdk/v1alpha1 kind : Guestbook metadata : name : example-guestbook spec : # Default values copied from <project_dir>/helm-charts/guestbook/values.yaml image : pullPolicy : Always repository : ibmcom/guestbook tag : v1 redis : port : 6379 slaveEnabled : true replicaCount : 2 service : port : 3000 type : LoadBalancer 2. Deploy the CRD \u00b6 Let Kubernetes know about the new custom resource definition (CRD) the operator will be watching. oc create -f deploy/crds/helm.operator-sdk_guestbooks_crd.yaml Verify the CRD install in OpenShift console: Alternatively, query using the following CLI commands: oc get crd guestbooks.helm.operator-sdk oc describe crd guestbooks.helm.operator-sdk 3. Build the code \u00b6 Use the generated Dockerfile under build directory for image build. FROM quay.io/operator-framework/helm-operator:v0.19.2 COPY watches.yaml ${ HOME } /watches.yaml COPY helm-charts/ ${ HOME } /helm-charts/ Run the operator sdk build command to build the image for the helm operator. operator-sdk build ${ IMG } INFO [ 0000 ] Building OCI image docker.io/rojanjose/guestbook-operator:v1.0.0 Sending build context to Docker daemon 41 .98kB Step 1 /3 : FROM quay.io/operator-framework/helm-operator:v0.19.2 v0.19.2: Pulling from operator-framework/helm-operator 41ae95b593e0: Pull complete f20f68829d13: Pull complete 05c2e7d4212e: Pull complete 66213365a0c9: Pull complete 09e5a7e28c6f: Pull complete Digest: sha256:0f1e104719267f687280d8640a6958c61510fae27a6937369c419b0dd2b91564 .... Verify the built image: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE rojanjose/guestbook-operator v1.0.0 d05f5e2c441e 7 seconds ago 200MB quay.io/operator-framework/helm-operator v0.19.2 11862329f28c 2 weeks ago 200MB Log into the docker registry and push image: docker login docker.io -u $DOCKER_USERNAME docker push ${ IMG } Replace the image name string in the operator.yaml file: sed -i 's|REPLACE_IMAGE|' ${ IMG } '|g' deploy/operator.yaml ( MacOS: ) sed -i \"\" 's|REPLACE_IMAGE|' ${ IMG } '|g' deploy/operator.yaml At this stage, the operator can be deployed with the available manifest files, however, we will explore the operator deloy with OLM features. 4. Deploy the Operator with the Operator Lifecycle Manager (OLM) \u00b6 Ensure OLM is enabled on the cluster by running this command: operator-sdk olm status --olm-namespace openshift-operator-lifecycle-manager Expected result: operator-sdk olm status --olm-namespace openshift-operator-lifecycle-manager I0813 23 :36:41.881438 14844 request.go:621 ] Throttling request took 1 .020925705s, request: GET:https://c100-e.us-east.containers.cloud.ibm.com:31941/apis/rbac.authorization.k8s.io/v1beta1?timeout = 32s INFO [ 0002 ] Fetching CRDs for version \"0.13.0\" INFO [ 0002 ] Fetching resources for version \"0.13.0\" INFO [ 0003 ] Successfully got OLM status for version \"0.13.0\" NAME NAMESPACE KIND STATUS installplans.operators.coreos.com CustomResourceDefinition Installed clusterserviceversions.operators.coreos.com CustomResourceDefinition Installed aggregate-olm-view ClusterRole Installed operatorgroups.operators.coreos.com CustomResourceDefinition Installed catalogsources.operators.coreos.com CustomResourceDefinition Installed subscriptions.operators.coreos.com CustomResourceDefinition Installed system:controller:operator-lifecycle-manager ClusterRole Installed aggregate-olm-edit ClusterRole Installed olm-operator-binding-olm ClusterRoleBinding clusterrolebindings.rbac.authorization.k8s.io \"olm-operator-binding-olm\" not found olm-operator-serviceaccount olm ServiceAccount serviceaccounts \"olm-operator-serviceaccount\" not found olm-operator olm Deployment deployments.apps \"olm-operator\" not found catalog-operator olm Deployment deployments.apps \"catalog-operator\" not found operators Namespace namespaces \"operators\" not found olm Namespace namespaces \"olm\" not found global-operators operators OperatorGroup operatorgroups.operators.coreos.com \"global-operators\" not found olm-operators olm OperatorGroup operatorgroups.operators.coreos.com \"olm-operators\" not found packageserver olm ClusterServiceVersion clusterserviceversions.operators.coreos.com \"packageserver\" not found operatorhubio-catalog olm CatalogSource catalogsources.operators.coreos.com \"operatorhubio-catalog\" not found [Note: OLM is partially enabled which is sufficient to complete this lab.] Create a bundle: operator-sdk generate bundle --version 1 .0.0 Output of the command: INFO [ 0000 ] Generating bundle manifests version 1 .0.0 Display name for the operator ( required ) : > Guestbook Operator Description for the operator ( required ) : > Demo helm operator for Guestbook Provider 's name for the operator (required): > IBM Any relevant URL for the provider name (optional): > https://github.com/rojanjose/guestbook-helm-operator Comma-separated list of keywords for your operator (required): > helm,operator,kubernetes,openshift Comma-separated list of maintainers and their emails (e.g. ' name1:email1, name2:email2 ' ) ( required ) : > Rojan:rojanjose@gmail.com INFO [ 0164 ] Bundle manifests generated successfully in deploy/olm-catalog/guestbook-operator-project INFO [ 0164 ] Building annotations.yaml INFO [ 0164 ] Writing annotations.yaml in /Users/operator/guestbook-operator-project/deploy/olm-catalog/guestbook-operator-project/metadata INFO [ 0164 ] Building Dockerfile INFO [ 0164 ] Writing bundle.Dockerfile in /Users/operator/guestbook-operator-project A bundle manifests directory deploy/olm-catalog/guestbook-operator-project/manifests containing a CSV and all CRDs in deploy/crds and a bundle metadata directory deploy/olm-catalog/guestbook-operator-project/metadata are generated. Create Project where operator OLM should be installed: oc new-project guest-operator-ns Output: Now using project \"guest-operator-ns\" on server \"https://c100-e.us-east.containers.cloud.ibm.com:31941\" . You can add applications to this project with the 'new-app' command. For example, try: oc new-app django-psql-example ... Create an OperatorGroup yaml definition: cat <<EOF >>deploy/operator_group.yaml apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: guestbook-og namespace: guest-operator-ns spec: targetNamespaces: - guest-operator-ns EOF Replace placeholder string with project guest-operator-ns in guestbook-operator.clusterserviceversion.yaml sed -i 's#namespace: placeholder#namespace: guest-operator-ns#' deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml or on Mac, sed -i \"\" 's#namespace: placeholder#namespace: guest-operator-ns#' deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml 5. Install the operator \u00b6 Create the Operator group: oc create -f deploy/operator_group.yaml Apply the Operator\u2019s CSV manifest to the specified namespace in the cluster: oc create -f deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml Create the role, role binding, and service account to grant resource permissions to the Operator to create the Guestbook type that the Operator manages: oc create -f deploy/service_account.yaml oc create -f deploy/role.yaml oc create -f deploy/role_binding.yaml Wait for few minutes for the Guestbook operator to complete the installation. oc get ClusterServiceVersion ClusterServiceVersion should show a PHASE value of Succeeded , $ oc get ClusterServiceVersion NAME DISPLAY VERSION REPLACES PHASE guestbook-operator-project.v1.0.0 Guestbook Operator 1 .0.0 Succeeded Check the list of Installed Operators under the project guest-operator-ns . Open the operator and validate that install succeeded. Now, create an instance of Guestbook helm chart. Click on Create instance icon. Goto Workloads > Pods to view the pods. You should see 2 frontend pods, 1 Redis master, 2 Redis slave and pod supporting the Guestbook operator OLM. 6. Update the Guestbook application instance \u00b6 Open the deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml and change the value of replicaCount to 4. Save the file and run the oc apply command: oc apply -f deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml Run oc get pods to validate the guesbook pod count: oc get podsNAME READY STATUS RESTARTS AGE example-guestbook-6fdb6776b-hdq64 1 /1 Running 0 41m example-guestbook-6fdb6776b-pktr8 1 /1 Running 0 8s example-guestbook-6fdb6776b-x2nqw 1 /1 Running 0 41m example-guestbook-6fdb6776b-xz8lp 1 /1 Running 0 77s guestbook-operator-project-767cc5686c-ksmxq 1 /1 Running 0 52m redis-master-68857cd57c-pwctp 1 /1 Running 0 41m redis-slave-bbd8d8545-6jk8m 1 /1 Running 0 41m redis-slave-bbd8d8545-k65wz 1 /1 Running 0 41m 7. Clean up \u00b6 Run the oc delete commands to remove the operator. oc delete -f deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml oc delete -f deploy/service_account.yaml oc delete -f deploy/role.yaml oc delete -f deploy/role_binding.yaml oc delete -f deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml oc delete -f deploy/operator_group.yaml oc delete -f deploy/crds/helm.operator-sdk_guestbooks_crd.yaml","title":"Create an Operator using an Existing Helm Chart"},{"location":"lab3-v0.19/#create-an-operator-using-an-existing-helm-chart","text":"The Operator Framework is an open source project that provides developer and runtime Kubernetes tools, enabling you to accelerate the development of an Operator. The Operator SDK provides the tools to build, test and package Operators. The following workflow is for a Helm operator using existing chart : Create a new operator project using the SDK Command Line Interface(CLI) Create a new (or add your existing) Helm chart for use by the operator\u2019s reconciling logic Use the SDK CLI to build and generate the operator deployment manifests Optionally add additional CRD\u2019s using the SDK CLI and repeat steps 2 and 3 Use the SDK bundle feature to package the operator for OLM deployment. Deploy, test and publish. In this lab, we will use the IBM Guestbook helm chart available here as the base to scaffold a new operator. Information of creating a new operator can be found here","title":"Create an Operator using an Existing Helm Chart"},{"location":"lab3-v0.19/#setup","text":"The lab requires you to have the operator-sdk installed. Login into the client CLI following these instructions . Run the command shown below to install the prerequisites: source < ( curl -s https://raw.githubusercontent.com/rojanjose/guestbook-helm-operator/master/scripts/operatorInstall.sh ) Check the command output to ensure the SDK version is correct. ... Checking prereqs version ... Go version: go version go1.14.4 linux/amd64 ----------------------------- Helm version: version.BuildInfo { Version: \"v3.0.3\" , GitCommit: \"ac925eb7279f4a6955df663a0128044a8a6b7593\" , GitTreeState: \"clean\" , GoVersion: \"go1.13.6\" } ----------------------------- Operator-sdk version: operator-sdk version: \"v0.19.2\" , commit: \"4282ce9acdef6d7a1e9f90832db4dc5a212ae850\" , kubernetes version: \"v1.18.2\" , go version: \"go1.13.10 linux/amd64\" Log into your OpenShift cluster . oc login --token = YQ2-mTJIWlz1gsWeI2tsO4CzHBbRSCQbH-IdA3tEFrM --server = https://c100-e.us-east.containers.cloud.ibm.com:32055","title":"Setup"},{"location":"lab3-v0.19/#create-the-operator","text":"","title":"Create the operator"},{"location":"lab3-v0.19/#1-create-a-new-project","text":"Export these environment variables prior to starting the project. export DOCKER_USERNAME = <your-docker-username> export OPERATOR_NAME = guestbook-operator export OPERATOR_PROJECT = guestbook-operator-project export OPERATOR_VERSION = v1.0.0 export IMG = docker.io/ ${ DOCKER_USERNAME } / ${ OPERATOR_NAME } : ${ OPERATOR_VERSION } Create a new project called guestbook-operator using the existing guestbook helm chart. The guestbook chart is available at the repo https://ibm.github.io/helm101/ . operator-sdk new $OPERATOR_PROJECT --type = helm --helm-chart = guestbook --helm-chart-repo = https://ibm.github.io/helm101/ cd $OPERATOR_PROJECT Output: INFO [ 0000 ] Creating new Helm operator 'guestbook-operator-project' . INFO [ 0000 ] Created helm-charts/guestbook INFO [ 0000 ] Generating RBAC rules I0813 23 :07:00.995286 11211 request.go:621 ] Throttling request took 1 .031369076s, request: GET:https://c100-e.us-east.containers.cloud.ibm.com:31941/apis/scheduling.k8s.io/v1?timeout = 32s WARN [ 0002 ] The RBAC rules generated in deploy/role.yaml are based on the chart 's default manifest. Some rules may be missing for resources that are only enabled with custom values, and some existing rules may be overly broad. Double check the rules generated in deploy/role.yaml to ensure they meet the operator' s permission requirements. INFO [ 0002 ] Created build/Dockerfile INFO [ 0002 ] Created deploy/service_account.yaml INFO [ 0002 ] Created deploy/role.yaml INFO [ 0002 ] Created deploy/role_binding.yaml INFO [ 0002 ] Created deploy/operator.yaml INFO [ 0002 ] Created deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml INFO [ 0002 ] Generated CustomResourceDefinition manifests. INFO [ 0002 ] Project creation complete. Review the code and customize the operator logic as required to obtain the desired results. By default, the Guestbook operator installs the configured helm chart watches the events shown in the watches.yaml . - group : helm.operator-sdk version : v1alpha1 kind : Guestbook chart : helm-charts/guestbook The custom resource (CR) file defines the properties used by operator while it creates an instance of the Guestbook application. These properties are derived from the values.yaml file in the Helm chart. apiVersion : helm.operator-sdk/v1alpha1 kind : Guestbook metadata : name : example-guestbook spec : # Default values copied from <project_dir>/helm-charts/guestbook/values.yaml image : pullPolicy : Always repository : ibmcom/guestbook tag : v1 redis : port : 6379 slaveEnabled : true replicaCount : 2 service : port : 3000 type : LoadBalancer","title":"1. Create a new project"},{"location":"lab3-v0.19/#2-deploy-the-crd","text":"Let Kubernetes know about the new custom resource definition (CRD) the operator will be watching. oc create -f deploy/crds/helm.operator-sdk_guestbooks_crd.yaml Verify the CRD install in OpenShift console: Alternatively, query using the following CLI commands: oc get crd guestbooks.helm.operator-sdk oc describe crd guestbooks.helm.operator-sdk","title":"2. Deploy the CRD"},{"location":"lab3-v0.19/#3-build-the-code","text":"Use the generated Dockerfile under build directory for image build. FROM quay.io/operator-framework/helm-operator:v0.19.2 COPY watches.yaml ${ HOME } /watches.yaml COPY helm-charts/ ${ HOME } /helm-charts/ Run the operator sdk build command to build the image for the helm operator. operator-sdk build ${ IMG } INFO [ 0000 ] Building OCI image docker.io/rojanjose/guestbook-operator:v1.0.0 Sending build context to Docker daemon 41 .98kB Step 1 /3 : FROM quay.io/operator-framework/helm-operator:v0.19.2 v0.19.2: Pulling from operator-framework/helm-operator 41ae95b593e0: Pull complete f20f68829d13: Pull complete 05c2e7d4212e: Pull complete 66213365a0c9: Pull complete 09e5a7e28c6f: Pull complete Digest: sha256:0f1e104719267f687280d8640a6958c61510fae27a6937369c419b0dd2b91564 .... Verify the built image: $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE rojanjose/guestbook-operator v1.0.0 d05f5e2c441e 7 seconds ago 200MB quay.io/operator-framework/helm-operator v0.19.2 11862329f28c 2 weeks ago 200MB Log into the docker registry and push image: docker login docker.io -u $DOCKER_USERNAME docker push ${ IMG } Replace the image name string in the operator.yaml file: sed -i 's|REPLACE_IMAGE|' ${ IMG } '|g' deploy/operator.yaml ( MacOS: ) sed -i \"\" 's|REPLACE_IMAGE|' ${ IMG } '|g' deploy/operator.yaml At this stage, the operator can be deployed with the available manifest files, however, we will explore the operator deloy with OLM features.","title":"3. Build the code"},{"location":"lab3-v0.19/#4-deploy-the-operator-with-the-operator-lifecycle-manager-olm","text":"Ensure OLM is enabled on the cluster by running this command: operator-sdk olm status --olm-namespace openshift-operator-lifecycle-manager Expected result: operator-sdk olm status --olm-namespace openshift-operator-lifecycle-manager I0813 23 :36:41.881438 14844 request.go:621 ] Throttling request took 1 .020925705s, request: GET:https://c100-e.us-east.containers.cloud.ibm.com:31941/apis/rbac.authorization.k8s.io/v1beta1?timeout = 32s INFO [ 0002 ] Fetching CRDs for version \"0.13.0\" INFO [ 0002 ] Fetching resources for version \"0.13.0\" INFO [ 0003 ] Successfully got OLM status for version \"0.13.0\" NAME NAMESPACE KIND STATUS installplans.operators.coreos.com CustomResourceDefinition Installed clusterserviceversions.operators.coreos.com CustomResourceDefinition Installed aggregate-olm-view ClusterRole Installed operatorgroups.operators.coreos.com CustomResourceDefinition Installed catalogsources.operators.coreos.com CustomResourceDefinition Installed subscriptions.operators.coreos.com CustomResourceDefinition Installed system:controller:operator-lifecycle-manager ClusterRole Installed aggregate-olm-edit ClusterRole Installed olm-operator-binding-olm ClusterRoleBinding clusterrolebindings.rbac.authorization.k8s.io \"olm-operator-binding-olm\" not found olm-operator-serviceaccount olm ServiceAccount serviceaccounts \"olm-operator-serviceaccount\" not found olm-operator olm Deployment deployments.apps \"olm-operator\" not found catalog-operator olm Deployment deployments.apps \"catalog-operator\" not found operators Namespace namespaces \"operators\" not found olm Namespace namespaces \"olm\" not found global-operators operators OperatorGroup operatorgroups.operators.coreos.com \"global-operators\" not found olm-operators olm OperatorGroup operatorgroups.operators.coreos.com \"olm-operators\" not found packageserver olm ClusterServiceVersion clusterserviceversions.operators.coreos.com \"packageserver\" not found operatorhubio-catalog olm CatalogSource catalogsources.operators.coreos.com \"operatorhubio-catalog\" not found [Note: OLM is partially enabled which is sufficient to complete this lab.] Create a bundle: operator-sdk generate bundle --version 1 .0.0 Output of the command: INFO [ 0000 ] Generating bundle manifests version 1 .0.0 Display name for the operator ( required ) : > Guestbook Operator Description for the operator ( required ) : > Demo helm operator for Guestbook Provider 's name for the operator (required): > IBM Any relevant URL for the provider name (optional): > https://github.com/rojanjose/guestbook-helm-operator Comma-separated list of keywords for your operator (required): > helm,operator,kubernetes,openshift Comma-separated list of maintainers and their emails (e.g. ' name1:email1, name2:email2 ' ) ( required ) : > Rojan:rojanjose@gmail.com INFO [ 0164 ] Bundle manifests generated successfully in deploy/olm-catalog/guestbook-operator-project INFO [ 0164 ] Building annotations.yaml INFO [ 0164 ] Writing annotations.yaml in /Users/operator/guestbook-operator-project/deploy/olm-catalog/guestbook-operator-project/metadata INFO [ 0164 ] Building Dockerfile INFO [ 0164 ] Writing bundle.Dockerfile in /Users/operator/guestbook-operator-project A bundle manifests directory deploy/olm-catalog/guestbook-operator-project/manifests containing a CSV and all CRDs in deploy/crds and a bundle metadata directory deploy/olm-catalog/guestbook-operator-project/metadata are generated. Create Project where operator OLM should be installed: oc new-project guest-operator-ns Output: Now using project \"guest-operator-ns\" on server \"https://c100-e.us-east.containers.cloud.ibm.com:31941\" . You can add applications to this project with the 'new-app' command. For example, try: oc new-app django-psql-example ... Create an OperatorGroup yaml definition: cat <<EOF >>deploy/operator_group.yaml apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: guestbook-og namespace: guest-operator-ns spec: targetNamespaces: - guest-operator-ns EOF Replace placeholder string with project guest-operator-ns in guestbook-operator.clusterserviceversion.yaml sed -i 's#namespace: placeholder#namespace: guest-operator-ns#' deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml or on Mac, sed -i \"\" 's#namespace: placeholder#namespace: guest-operator-ns#' deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml","title":"4. Deploy the Operator with the Operator Lifecycle Manager (OLM)"},{"location":"lab3-v0.19/#5-install-the-operator","text":"Create the Operator group: oc create -f deploy/operator_group.yaml Apply the Operator\u2019s CSV manifest to the specified namespace in the cluster: oc create -f deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml Create the role, role binding, and service account to grant resource permissions to the Operator to create the Guestbook type that the Operator manages: oc create -f deploy/service_account.yaml oc create -f deploy/role.yaml oc create -f deploy/role_binding.yaml Wait for few minutes for the Guestbook operator to complete the installation. oc get ClusterServiceVersion ClusterServiceVersion should show a PHASE value of Succeeded , $ oc get ClusterServiceVersion NAME DISPLAY VERSION REPLACES PHASE guestbook-operator-project.v1.0.0 Guestbook Operator 1 .0.0 Succeeded Check the list of Installed Operators under the project guest-operator-ns . Open the operator and validate that install succeeded. Now, create an instance of Guestbook helm chart. Click on Create instance icon. Goto Workloads > Pods to view the pods. You should see 2 frontend pods, 1 Redis master, 2 Redis slave and pod supporting the Guestbook operator OLM.","title":"5. Install the operator"},{"location":"lab3-v0.19/#6-update-the-guestbook-application-instance","text":"Open the deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml and change the value of replicaCount to 4. Save the file and run the oc apply command: oc apply -f deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml Run oc get pods to validate the guesbook pod count: oc get podsNAME READY STATUS RESTARTS AGE example-guestbook-6fdb6776b-hdq64 1 /1 Running 0 41m example-guestbook-6fdb6776b-pktr8 1 /1 Running 0 8s example-guestbook-6fdb6776b-x2nqw 1 /1 Running 0 41m example-guestbook-6fdb6776b-xz8lp 1 /1 Running 0 77s guestbook-operator-project-767cc5686c-ksmxq 1 /1 Running 0 52m redis-master-68857cd57c-pwctp 1 /1 Running 0 41m redis-slave-bbd8d8545-6jk8m 1 /1 Running 0 41m redis-slave-bbd8d8545-k65wz 1 /1 Running 0 41m","title":"6. Update the Guestbook application instance"},{"location":"lab3-v0.19/#7-clean-up","text":"Run the oc delete commands to remove the operator. oc delete -f deploy/crds/helm.operator-sdk_v1alpha1_guestbook_cr.yaml oc delete -f deploy/service_account.yaml oc delete -f deploy/role.yaml oc delete -f deploy/role_binding.yaml oc delete -f deploy/olm-catalog/guestbook-operator-project/manifests/guestbook-operator-project.clusterserviceversion.yaml oc delete -f deploy/operator_group.yaml oc delete -f deploy/crds/helm.operator-sdk_guestbooks_crd.yaml","title":"7. Clean up"},{"location":"lab3/","text":"Create an Operator using an Existing Helm Chart \u00b6 The Operator Framework is an open source project that provides developer and runtime Kubernetes tools, enabling you to accelerate the development of an Operator. The Operator SDK provides the tools to build, test and package Operators. The following workflow is to build an operator using an existing Helm chart : Create a new operator project and initialize it using the SDK Command Line Interface(CLI) Create the API to generate the CRD files for the chart. Build the Operator container image and push it to a registry. Apply the CRD in the cluster and deploy the operator image. Deploy the operand by applying the custom resource (CR) into the cluster. Cleanup the deployment. In this lab, we will use the IBM Guestbook helm chart available here as the base to scaffold a new operator. Information on creating a new operator can be found here Operator SDK made several technology and architecture changes with the release of v1.0 which as listed here . Setup \u00b6 The following must be done before you can get started on the lab: Create your lab environment by following the steps found here The lab requires a newer version of the operator-sdk installed. In the lab terminal, run the commands shown below to install the prerequisites: source < ( curl -s https://raw.githubusercontent.com/ibm/kubernetes-operators/master/src/scripts/operatorInstall.sh ) export PATH = \" ${ HOME } /bin: ${ PATH } \" $ source <(curl -s https://raw.githubusercontent.com/ibm/kubernetes-operators/master/src/scripts/operatorInstall.sh) Downloading operaror-sdk-v1.3.0-linux_amd64 ... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 632 100 632 0 0 1876 0 --:--:-- --:--:-- --:--:-- 1875 100 64.8M 100 64.8M 0 0 61.9M 0 0:00:01 0:00:01 --:--:-- 61.9M operaror-sdk-v1.3.0-linux_amd64 downloaded. ...... Run a version check after the operator-sdk installation is complete: operator-sdk version $ operator-sdk version operator-sdk version: \"v1.3.0\", commit: \"1abf57985b43bf6a59dcd18147b3c574fa57d3f6\", kubernetes version: \"1.19.4\", go version: \"go1.15.5\", GOOS: \"linux\", GOARCH: \"amd64\" Log into the OpenShift cluster: Scroll down on the Quick Links and Common commands page until you see a terminal command block with green text and a description above it that says Log in to your OpenShift cluster. Click on the command and it will automatically paste into your terminal and execute. This lab uses docker registry to container image storage. Create a new docker hub id, if you do not have one. Create the operator \u00b6 1. Create a new project & initialize it using SDK \u00b6 Certain parameters will be used repetitively. Export these parameters as environment variables prior to starting the project. Replace <your-docker-username> with your docker hub id. export DOCKER_USERNAME = <your-docker-username> Set names for the operator, project and operator version. The operator container images is built using these values. export OPERATOR_NAME = guestbook-operator export OPERATOR_PROJECT = guestbook-operator-project export OPERATOR_VERSION = v1.0.0 export IMAGE = docker.io/ ${ DOCKER_USERNAME } / ${ OPERATOR_NAME } : ${ OPERATOR_VERSION } Create the project directory for the operator. mkdir -p ${ OPERATOR_PROJECT } cd ${ OPERATOR_PROJECT } Use the operator SDK to initialize the project. Specify the plugin and API group as the parameters for this command. operator-sdk init --plugins = helm --domain guestbook.ibm.com $ operator-sdk init --plugins=helm --domain guestbook.ibm.com Next: define a resource with: $ operator-sdk create api The initialization step create a scaffolding with the operator boiler plate code. At high level, this creates the config directory, watches.yaml and the place holder for the helm chart. Use the command tree . to view the complete directory structure as shown in the block below: . \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 PROJECT \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 default \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager_auth_proxy_patch.yaml \u2502 \u251c\u2500\u2500 manager \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager.yaml \u2502 \u251c\u2500\u2500 prometheus \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 monitor.yaml \u2502 \u251c\u2500\u2500 rbac \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_client_clusterrole.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_service.yaml \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 role.yaml \u2502 \u2502 \u2514\u2500\u2500 role_binding.yaml \u2502 \u2514\u2500\u2500 scorecard \u2502 \u251c\u2500\u2500 bases \u2502 \u2502 \u2514\u2500\u2500 config.yaml \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patches \u2502 \u251c\u2500\u2500 basic.config.yaml \u2502 \u2514\u2500\u2500 olm.config.yaml \u251c\u2500\u2500 helm-charts \u2514\u2500\u2500 watches.yaml Operator SDK uses the kubernetes Kustomize tool for managing the deployment of yaml files, hence you see the kustomization.yaml in all the directories. config/default and confg/manager contains the specification to inject the controller manager container into the operator pod as a side car. The confg/rbac folder contains a set of default access control rules. Review the Makefile to understand the operator-sdk , kustomize and docker commands executed for various tasks. 2. Create the API to generate the CRD files for the chart. \u00b6 Next step, create the API artifacts. Provide the name and the location of the helm chart as input parameters to this command. This command will create the crd folder with the custom resource definition for the Guestbook operator. The command picks the latest version of the helm chart, if the helm version parameter is ignored. operator-sdk create api --helm-chart=guestbook --helm-chart-repo=https://raw.githubusercontent.com/IBM/helm101/master/ operator-sdk create api --helm-chart=guestbook --helm-chart-repo=https://raw.githubusercontent.com/IBM/helm101/master/ Created helm-charts/guestbook Generating RBAC rules I0202 15:46:05.545032 48799 request.go:645] Throttling request took 1.005544854s, request: GET:https://c107-e.us-south.containers.cloud.ibm.com:30606/apis/extensions/v1beta1?timeout=32s WARN[0003] The RBAC rules generated in config/rbac/role.yaml are based on the chart's default manifest. Some rules may be missing for resources that are only enabled with custom values, and some existing rules may be overly broad. Double check the rules generated in config/rbac/role.yaml to ensure they meet the operator's permission requirements. Check the new additions to the scaffolding using the tree . command: . \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 PROJECT \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 crd \u2502 \u2502 \u251c\u2500\u2500 bases \u2502 \u2502 \u2502 \u2514\u2500\u2500 charts.guestbook.ibm.com_guestbooks.yaml \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml \u2502 \u251c\u2500\u2500 default \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager_auth_proxy_patch.yaml \u2502 \u251c\u2500\u2500 manager \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager.yaml \u2502 \u251c\u2500\u2500 prometheus \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 monitor.yaml \u2502 \u251c\u2500\u2500 rbac \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_client_clusterrole.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_service.yaml \u2502 \u2502 \u251c\u2500\u2500 guestbook_editor_role.yaml \u2502 \u2502 \u251c\u2500\u2500 guestbook_viewer_role.yaml \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 role.yaml \u2502 \u2502 \u2514\u2500\u2500 role_binding.yaml \u2502 \u251c\u2500\u2500 samples \u2502 \u2502 \u2514\u2500\u2500 charts_v1alpha1_guestbook.yaml \u2502 \u2514\u2500\u2500 scorecard \u2502 \u251c\u2500\u2500 bases \u2502 \u2502 \u2514\u2500\u2500 config.yaml \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patches \u2502 \u251c\u2500\u2500 basic.config.yaml \u2502 \u2514\u2500\u2500 olm.config.yaml \u251c\u2500\u2500 helm-charts \u2502 \u2514\u2500\u2500 guestbook \u2502 \u251c\u2500\u2500 Chart.yaml \u2502 \u251c\u2500\u2500 LICENSE \u2502 \u251c\u2500\u2500 README.md \u2502 \u251c\u2500\u2500 templates \u2502 \u2502 \u251c\u2500\u2500 NOTES.txt \u2502 \u2502 \u251c\u2500\u2500 _helpers.tpl \u2502 \u2502 \u251c\u2500\u2500 guestbook-deployment.yaml \u2502 \u2502 \u251c\u2500\u2500 guestbook-service.yaml \u2502 \u2502 \u251c\u2500\u2500 redis-master-deployment.yaml \u2502 \u2502 \u251c\u2500\u2500 redis-master-service.yaml \u2502 \u2502 \u251c\u2500\u2500 redis-slave-deployment.yaml \u2502 \u2502 \u2514\u2500\u2500 redis-slave-service.yaml \u2502 \u2514\u2500\u2500 values.yaml \u2514\u2500\u2500 watches.yaml View the contents of the CRD. Note the values for names and schema.openAPIV3Schema.properties . more config/crd/bases/charts.guestbook.ibm.com_guestbooks.yaml apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: guestbooks.charts.guestbook.ibm.com spec: group: charts.guestbook.ibm.com names: kind: Guestbook listKind: GuestbookList plural: guestbooks singular: guestbook scope: Namespaced versions: - name: v1alpha1 schema: openAPIV3Schema: ... 3. Build the Operator container image and push it to registry. \u00b6 Login into the docker registry using your personal id and password. docker login docker.io -u $DOCKER_USERNAME $ docker login docker.io -u $DOCKER_USERNAME Password: WARNING! Your password will be stored unencrypted in /home/student/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded Build the Guestbook operator container image and push image to the docker hub registry. make docker-build docker-push IMG = ${ IMAGE } make docker-build docker-push IMG=${IMAGE} docker build . -t docker.io/rojanjose/guestbook-operator:v1.0.0 [+] Building 4.2s (9/9) FINISHED => [internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => [internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 237B ........... ........... 753e76240780: Pushed 4a3bef90e857: Pushed d0e9a59c2057: Pushed 1d8db7e222a6: Pushed 00af10937683: Pushed 3aa55ff7bca1: Pushed v1.0.0: digest: sha256:c0724c7f31a748094621b7623a81fae107511c23819b729f25878f7e5a7377dd size: 1984 You can view the local docker images by running: docker images $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE rojanjose/guestbook-operator v1.0.0 590c0196c2b6 10 seconds ago 160MB quay.io/operator-framework/helm-operator v1.3.0 57683a970d10 6 weeks ago 160MB 4. Apply the CRD in the cluster and deploy the operator image. \u00b6 Install the Guestbook customer resource definition using the make install command: make install make install /home/student/guestbook-operator-project/bin/kustomize build config/crd | kubectl apply -f - customresourcedefinition.apiextensions.k8s.io/guestbooks.charts.guestbook.ibm.com created View the deployed CRD oc describe CustomResourceDefinition guestbooks.charts.guestbook.ibm.com Next step is to deploy the operator. Note that the operator is installed in its own namespace guestbook-operator-project-system . make deploy IMG=${IMAGE} $ make deploy IMG=${IMAGE} cd config/manager && /home/student/guestbook-operator-project/bin/kustomize edit set image controller=docker.io/rojanjose/guestbook-operator:v1.0.0 /home/student/guestbook-operator-project/bin/kustomize build config/default | kubectl apply -f - namespace/guestbook-operator-project-system created customresourcedefinition.apiextensions.k8s.io/guestbooks.charts.guestbook.ibm.com unchanged role.rbac.authorization.k8s.io/guestbook-operator-project-leader-election-role created clusterrole.rbac.authorization.k8s.io/guestbook-operator-project-manager-role created clusterrole.rbac.authorization.k8s.io/guestbook-operator-project-metrics-reader created clusterrole.rbac.authorization.k8s.io/guestbook-operator-project-proxy-role created rolebinding.rbac.authorization.k8s.io/guestbook-operator-project-leader-election-rolebinding created clusterrolebinding.rbac.authorization.k8s.io/guestbook-operator-project-manager-rolebinding created clusterrolebinding.rbac.authorization.k8s.io/guestbook-operator-project-proxy-rolebinding created service/guestbook-operator-project-controller-manager-metrics-service created deployment.apps/guestbook-operator-project-controller-manager created View of what got deployed: oc get all -n ${ OPERATOR_PROJECT } -system $ oc get all -n ${OPERATOR_PROJECT}-system NAME READY STATUS RESTARTS AGE pod/guestbook-operator-project-controller-manager-7bc6f986dd-2r898 2/2 Running 0 2m24s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-operator-project-controller-manager-metrics-service ClusterIP 172.21.110.64 <none> 8443/TCP 2m24s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-operator-project-controller-manager 1/1 1 1 2m24s NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-operator-project-controller-manager-7bc6f986dd 1 1 1 2m24s 5. Deploy the operand by applying the custom resource (CR) into the cluster. \u00b6 Create a new project called guestbook where Guestbook application will be deployed. oc new-project guestbook $ oc new-project guestbook Now using project \"guestbook\" on server \"https://c107-e.us-south.containers.cloud.ibm.com:30606\". You can add applications to this project with the 'new-app' command. For example, try: oc new-app ruby~https://github.com/sclorg/ruby-ex.git to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application: kubectl create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node An example custom resource yaml file was automatically generated under the config/samples directory as part of the create API step earlier. This is based on the default values.yaml from the Guestbook helm chart under helm-charts/guestbook/values.yaml . Let's use this file to create the operand. oc apply -f config/samples/charts_v1alpha1_guestbook.yaml $ oc apply -f config/samples/charts_v1alpha1_guestbook.yaml guestbook.charts.guestbook.ibm.com/guestbook-sample created Outcome of the operand deploy can be viewed by running the command: oc get all -n guestbook $ oc get all -n guestbook NAME READY STATUS RESTARTS AGE pod/guestbook-sample-8594c8dc46-bl7sm 1/1 Running 0 75s pod/guestbook-sample-8594c8dc46-qwgkv 1/1 Running 0 75s pod/redis-master-68857cd57c-bjxt5 1/1 Running 0 75s pod/redis-slave-bbd8d8545-57944 1/1 Running 0 75s pod/redis-slave-bbd8d8545-rxqc5 1/1 Running 0 75s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-sample LoadBalancer 172.21.41.67 169.45.217.90 3000:30940/TCP 75s service/redis-master ClusterIP 172.21.206.242 <none> 6379/TCP 75s service/redis-slave ClusterIP 172.21.133.74 <none> 6379/TCP 75s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-sample 2/2 2 2 75s deployment.apps/redis-master 1/1 1 1 75s deployment.apps/redis-slave 2/2 2 2 75s NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-sample-8594c8dc46 2 2 2 75s replicaset.apps/redis-master-68857cd57c 1 1 1 75s replicaset.apps/redis-slave-bbd8d8545 2 2 2 75s Validate the Guestbook application is running by accessing it with the following commands: HOSTNAME = ` oc get nodes -ojsonpath = '{.items[0].metadata.labels.ibm-cloud\\.kubernetes\\.io\\/external-ip}' ` SERVICEPORT = ` oc get svc guestbook-sample -o = jsonpath = '{.spec.ports[0].nodePort}' ` echo \"http:// $HOSTNAME : $SERVICEPORT \" http://169.45.242.104:30940 Copy and paste the above URL in a new browser tab to get to the Guestbook landing page as shown below: Open the OpenShift console to view the artificats created as part of this exerice. Guestbook operator pod: Guestbook application pods: 6. Cleanup the deployment. \u00b6 Remove the Guestbook application by deleting the customer resource (CR). oc delete -f config/samples/charts_v1alpha1_guestbook.yaml $ oc delete -f config/samples/charts_v1alpha1_guestbook.yaml guestbook.charts.guestbook.ibm.com \"guestbook-sample\" deleted $ oc get all -n guestbook No resources found in guestbook namespace. $ oc delete project guestbook project.project.openshift.io \"guestbook\" deleted Finally, to delete the CRDs, run the make undeploy command: make undeploy $ make undeploy /home/student/guestbook-operator-project/bin/kustomize build config/default | kubectl delete -f - namespace \"gb-helm-operator-system\" deleted customresourcedefinition.apiextensions.k8s.io \"guestbooks.charts.guestbook.ibm.com\" deleted role.rbac.authorization.k8s.io \"gb-helm-operator-leader-election-role\" deleted clusterrole.rbac.authorization.k8s.io \"gb-helm-operator-manager-role\" deleted clusterrole.rbac.authorization.k8s.io \"gb-helm-operator-metrics-reader\" deleted clusterrole.rbac.authorization.k8s.io \"gb-helm-operator-proxy-role\" deleted rolebinding.rbac.authorization.k8s.io \"gb-helm-operator-leader-election-rolebinding\" deleted clusterrolebinding.rbac.authorization.k8s.io \"gb-helm-operator-manager-rolebinding\" deleted clusterrolebinding.rbac.authorization.k8s.io \"gb-helm-operator-proxy-rolebinding\" deleted service \"gb-helm-operator-controller-manager-metrics-service\" deleted deployment.apps \"gb-helm-operator-controller-manager\" deleted This concludes the Helm Operator lab. Go here for additional information on building operators using Helm.","title":"Operator from Helm"},{"location":"lab3/#create-an-operator-using-an-existing-helm-chart","text":"The Operator Framework is an open source project that provides developer and runtime Kubernetes tools, enabling you to accelerate the development of an Operator. The Operator SDK provides the tools to build, test and package Operators. The following workflow is to build an operator using an existing Helm chart : Create a new operator project and initialize it using the SDK Command Line Interface(CLI) Create the API to generate the CRD files for the chart. Build the Operator container image and push it to a registry. Apply the CRD in the cluster and deploy the operator image. Deploy the operand by applying the custom resource (CR) into the cluster. Cleanup the deployment. In this lab, we will use the IBM Guestbook helm chart available here as the base to scaffold a new operator. Information on creating a new operator can be found here Operator SDK made several technology and architecture changes with the release of v1.0 which as listed here .","title":"Create an Operator using an Existing Helm Chart"},{"location":"lab3/#setup","text":"The following must be done before you can get started on the lab: Create your lab environment by following the steps found here The lab requires a newer version of the operator-sdk installed. In the lab terminal, run the commands shown below to install the prerequisites: source < ( curl -s https://raw.githubusercontent.com/ibm/kubernetes-operators/master/src/scripts/operatorInstall.sh ) export PATH = \" ${ HOME } /bin: ${ PATH } \" $ source <(curl -s https://raw.githubusercontent.com/ibm/kubernetes-operators/master/src/scripts/operatorInstall.sh) Downloading operaror-sdk-v1.3.0-linux_amd64 ... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 632 100 632 0 0 1876 0 --:--:-- --:--:-- --:--:-- 1875 100 64.8M 100 64.8M 0 0 61.9M 0 0:00:01 0:00:01 --:--:-- 61.9M operaror-sdk-v1.3.0-linux_amd64 downloaded. ...... Run a version check after the operator-sdk installation is complete: operator-sdk version $ operator-sdk version operator-sdk version: \"v1.3.0\", commit: \"1abf57985b43bf6a59dcd18147b3c574fa57d3f6\", kubernetes version: \"1.19.4\", go version: \"go1.15.5\", GOOS: \"linux\", GOARCH: \"amd64\" Log into the OpenShift cluster: Scroll down on the Quick Links and Common commands page until you see a terminal command block with green text and a description above it that says Log in to your OpenShift cluster. Click on the command and it will automatically paste into your terminal and execute. This lab uses docker registry to container image storage. Create a new docker hub id, if you do not have one.","title":"Setup"},{"location":"lab3/#create-the-operator","text":"","title":"Create the operator"},{"location":"lab3/#1-create-a-new-project-initialize-it-using-sdk","text":"Certain parameters will be used repetitively. Export these parameters as environment variables prior to starting the project. Replace <your-docker-username> with your docker hub id. export DOCKER_USERNAME = <your-docker-username> Set names for the operator, project and operator version. The operator container images is built using these values. export OPERATOR_NAME = guestbook-operator export OPERATOR_PROJECT = guestbook-operator-project export OPERATOR_VERSION = v1.0.0 export IMAGE = docker.io/ ${ DOCKER_USERNAME } / ${ OPERATOR_NAME } : ${ OPERATOR_VERSION } Create the project directory for the operator. mkdir -p ${ OPERATOR_PROJECT } cd ${ OPERATOR_PROJECT } Use the operator SDK to initialize the project. Specify the plugin and API group as the parameters for this command. operator-sdk init --plugins = helm --domain guestbook.ibm.com $ operator-sdk init --plugins=helm --domain guestbook.ibm.com Next: define a resource with: $ operator-sdk create api The initialization step create a scaffolding with the operator boiler plate code. At high level, this creates the config directory, watches.yaml and the place holder for the helm chart. Use the command tree . to view the complete directory structure as shown in the block below: . \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 PROJECT \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 default \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager_auth_proxy_patch.yaml \u2502 \u251c\u2500\u2500 manager \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager.yaml \u2502 \u251c\u2500\u2500 prometheus \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 monitor.yaml \u2502 \u251c\u2500\u2500 rbac \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_client_clusterrole.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_service.yaml \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 role.yaml \u2502 \u2502 \u2514\u2500\u2500 role_binding.yaml \u2502 \u2514\u2500\u2500 scorecard \u2502 \u251c\u2500\u2500 bases \u2502 \u2502 \u2514\u2500\u2500 config.yaml \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patches \u2502 \u251c\u2500\u2500 basic.config.yaml \u2502 \u2514\u2500\u2500 olm.config.yaml \u251c\u2500\u2500 helm-charts \u2514\u2500\u2500 watches.yaml Operator SDK uses the kubernetes Kustomize tool for managing the deployment of yaml files, hence you see the kustomization.yaml in all the directories. config/default and confg/manager contains the specification to inject the controller manager container into the operator pod as a side car. The confg/rbac folder contains a set of default access control rules. Review the Makefile to understand the operator-sdk , kustomize and docker commands executed for various tasks.","title":"1. Create a new project &amp; initialize it using SDK"},{"location":"lab3/#2-create-the-api-to-generate-the-crd-files-for-the-chart","text":"Next step, create the API artifacts. Provide the name and the location of the helm chart as input parameters to this command. This command will create the crd folder with the custom resource definition for the Guestbook operator. The command picks the latest version of the helm chart, if the helm version parameter is ignored. operator-sdk create api --helm-chart=guestbook --helm-chart-repo=https://raw.githubusercontent.com/IBM/helm101/master/ operator-sdk create api --helm-chart=guestbook --helm-chart-repo=https://raw.githubusercontent.com/IBM/helm101/master/ Created helm-charts/guestbook Generating RBAC rules I0202 15:46:05.545032 48799 request.go:645] Throttling request took 1.005544854s, request: GET:https://c107-e.us-south.containers.cloud.ibm.com:30606/apis/extensions/v1beta1?timeout=32s WARN[0003] The RBAC rules generated in config/rbac/role.yaml are based on the chart's default manifest. Some rules may be missing for resources that are only enabled with custom values, and some existing rules may be overly broad. Double check the rules generated in config/rbac/role.yaml to ensure they meet the operator's permission requirements. Check the new additions to the scaffolding using the tree . command: . \u251c\u2500\u2500 Dockerfile \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 PROJECT \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 crd \u2502 \u2502 \u251c\u2500\u2500 bases \u2502 \u2502 \u2502 \u2514\u2500\u2500 charts.guestbook.ibm.com_guestbooks.yaml \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml \u2502 \u251c\u2500\u2500 default \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager_auth_proxy_patch.yaml \u2502 \u251c\u2500\u2500 manager \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 manager.yaml \u2502 \u251c\u2500\u2500 prometheus \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u2514\u2500\u2500 monitor.yaml \u2502 \u251c\u2500\u2500 rbac \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_client_clusterrole.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 auth_proxy_service.yaml \u2502 \u2502 \u251c\u2500\u2500 guestbook_editor_role.yaml \u2502 \u2502 \u251c\u2500\u2500 guestbook_viewer_role.yaml \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role.yaml \u2502 \u2502 \u251c\u2500\u2500 leader_election_role_binding.yaml \u2502 \u2502 \u251c\u2500\u2500 role.yaml \u2502 \u2502 \u2514\u2500\u2500 role_binding.yaml \u2502 \u251c\u2500\u2500 samples \u2502 \u2502 \u2514\u2500\u2500 charts_v1alpha1_guestbook.yaml \u2502 \u2514\u2500\u2500 scorecard \u2502 \u251c\u2500\u2500 bases \u2502 \u2502 \u2514\u2500\u2500 config.yaml \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patches \u2502 \u251c\u2500\u2500 basic.config.yaml \u2502 \u2514\u2500\u2500 olm.config.yaml \u251c\u2500\u2500 helm-charts \u2502 \u2514\u2500\u2500 guestbook \u2502 \u251c\u2500\u2500 Chart.yaml \u2502 \u251c\u2500\u2500 LICENSE \u2502 \u251c\u2500\u2500 README.md \u2502 \u251c\u2500\u2500 templates \u2502 \u2502 \u251c\u2500\u2500 NOTES.txt \u2502 \u2502 \u251c\u2500\u2500 _helpers.tpl \u2502 \u2502 \u251c\u2500\u2500 guestbook-deployment.yaml \u2502 \u2502 \u251c\u2500\u2500 guestbook-service.yaml \u2502 \u2502 \u251c\u2500\u2500 redis-master-deployment.yaml \u2502 \u2502 \u251c\u2500\u2500 redis-master-service.yaml \u2502 \u2502 \u251c\u2500\u2500 redis-slave-deployment.yaml \u2502 \u2502 \u2514\u2500\u2500 redis-slave-service.yaml \u2502 \u2514\u2500\u2500 values.yaml \u2514\u2500\u2500 watches.yaml View the contents of the CRD. Note the values for names and schema.openAPIV3Schema.properties . more config/crd/bases/charts.guestbook.ibm.com_guestbooks.yaml apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: guestbooks.charts.guestbook.ibm.com spec: group: charts.guestbook.ibm.com names: kind: Guestbook listKind: GuestbookList plural: guestbooks singular: guestbook scope: Namespaced versions: - name: v1alpha1 schema: openAPIV3Schema: ...","title":"2. Create the API to generate the CRD files for the chart."},{"location":"lab3/#3-build-the-operator-container-image-and-push-it-to-registry","text":"Login into the docker registry using your personal id and password. docker login docker.io -u $DOCKER_USERNAME $ docker login docker.io -u $DOCKER_USERNAME Password: WARNING! Your password will be stored unencrypted in /home/student/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded Build the Guestbook operator container image and push image to the docker hub registry. make docker-build docker-push IMG = ${ IMAGE } make docker-build docker-push IMG=${IMAGE} docker build . -t docker.io/rojanjose/guestbook-operator:v1.0.0 [+] Building 4.2s (9/9) FINISHED => [internal] load .dockerignore 0.0s => => transferring context: 2B 0.0s => [internal] load build definition from Dockerfile 0.0s => => transferring dockerfile: 237B ........... ........... 753e76240780: Pushed 4a3bef90e857: Pushed d0e9a59c2057: Pushed 1d8db7e222a6: Pushed 00af10937683: Pushed 3aa55ff7bca1: Pushed v1.0.0: digest: sha256:c0724c7f31a748094621b7623a81fae107511c23819b729f25878f7e5a7377dd size: 1984 You can view the local docker images by running: docker images $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE rojanjose/guestbook-operator v1.0.0 590c0196c2b6 10 seconds ago 160MB quay.io/operator-framework/helm-operator v1.3.0 57683a970d10 6 weeks ago 160MB","title":"3. Build the Operator container image and push it to registry."},{"location":"lab3/#4-apply-the-crd-in-the-cluster-and-deploy-the-operator-image","text":"Install the Guestbook customer resource definition using the make install command: make install make install /home/student/guestbook-operator-project/bin/kustomize build config/crd | kubectl apply -f - customresourcedefinition.apiextensions.k8s.io/guestbooks.charts.guestbook.ibm.com created View the deployed CRD oc describe CustomResourceDefinition guestbooks.charts.guestbook.ibm.com Next step is to deploy the operator. Note that the operator is installed in its own namespace guestbook-operator-project-system . make deploy IMG=${IMAGE} $ make deploy IMG=${IMAGE} cd config/manager && /home/student/guestbook-operator-project/bin/kustomize edit set image controller=docker.io/rojanjose/guestbook-operator:v1.0.0 /home/student/guestbook-operator-project/bin/kustomize build config/default | kubectl apply -f - namespace/guestbook-operator-project-system created customresourcedefinition.apiextensions.k8s.io/guestbooks.charts.guestbook.ibm.com unchanged role.rbac.authorization.k8s.io/guestbook-operator-project-leader-election-role created clusterrole.rbac.authorization.k8s.io/guestbook-operator-project-manager-role created clusterrole.rbac.authorization.k8s.io/guestbook-operator-project-metrics-reader created clusterrole.rbac.authorization.k8s.io/guestbook-operator-project-proxy-role created rolebinding.rbac.authorization.k8s.io/guestbook-operator-project-leader-election-rolebinding created clusterrolebinding.rbac.authorization.k8s.io/guestbook-operator-project-manager-rolebinding created clusterrolebinding.rbac.authorization.k8s.io/guestbook-operator-project-proxy-rolebinding created service/guestbook-operator-project-controller-manager-metrics-service created deployment.apps/guestbook-operator-project-controller-manager created View of what got deployed: oc get all -n ${ OPERATOR_PROJECT } -system $ oc get all -n ${OPERATOR_PROJECT}-system NAME READY STATUS RESTARTS AGE pod/guestbook-operator-project-controller-manager-7bc6f986dd-2r898 2/2 Running 0 2m24s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-operator-project-controller-manager-metrics-service ClusterIP 172.21.110.64 <none> 8443/TCP 2m24s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-operator-project-controller-manager 1/1 1 1 2m24s NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-operator-project-controller-manager-7bc6f986dd 1 1 1 2m24s","title":"4. Apply the CRD in the cluster and deploy the operator image."},{"location":"lab3/#5-deploy-the-operand-by-applying-the-custom-resource-cr-into-the-cluster","text":"Create a new project called guestbook where Guestbook application will be deployed. oc new-project guestbook $ oc new-project guestbook Now using project \"guestbook\" on server \"https://c107-e.us-south.containers.cloud.ibm.com:30606\". You can add applications to this project with the 'new-app' command. For example, try: oc new-app ruby~https://github.com/sclorg/ruby-ex.git to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application: kubectl create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node An example custom resource yaml file was automatically generated under the config/samples directory as part of the create API step earlier. This is based on the default values.yaml from the Guestbook helm chart under helm-charts/guestbook/values.yaml . Let's use this file to create the operand. oc apply -f config/samples/charts_v1alpha1_guestbook.yaml $ oc apply -f config/samples/charts_v1alpha1_guestbook.yaml guestbook.charts.guestbook.ibm.com/guestbook-sample created Outcome of the operand deploy can be viewed by running the command: oc get all -n guestbook $ oc get all -n guestbook NAME READY STATUS RESTARTS AGE pod/guestbook-sample-8594c8dc46-bl7sm 1/1 Running 0 75s pod/guestbook-sample-8594c8dc46-qwgkv 1/1 Running 0 75s pod/redis-master-68857cd57c-bjxt5 1/1 Running 0 75s pod/redis-slave-bbd8d8545-57944 1/1 Running 0 75s pod/redis-slave-bbd8d8545-rxqc5 1/1 Running 0 75s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/guestbook-sample LoadBalancer 172.21.41.67 169.45.217.90 3000:30940/TCP 75s service/redis-master ClusterIP 172.21.206.242 <none> 6379/TCP 75s service/redis-slave ClusterIP 172.21.133.74 <none> 6379/TCP 75s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/guestbook-sample 2/2 2 2 75s deployment.apps/redis-master 1/1 1 1 75s deployment.apps/redis-slave 2/2 2 2 75s NAME DESIRED CURRENT READY AGE replicaset.apps/guestbook-sample-8594c8dc46 2 2 2 75s replicaset.apps/redis-master-68857cd57c 1 1 1 75s replicaset.apps/redis-slave-bbd8d8545 2 2 2 75s Validate the Guestbook application is running by accessing it with the following commands: HOSTNAME = ` oc get nodes -ojsonpath = '{.items[0].metadata.labels.ibm-cloud\\.kubernetes\\.io\\/external-ip}' ` SERVICEPORT = ` oc get svc guestbook-sample -o = jsonpath = '{.spec.ports[0].nodePort}' ` echo \"http:// $HOSTNAME : $SERVICEPORT \" http://169.45.242.104:30940 Copy and paste the above URL in a new browser tab to get to the Guestbook landing page as shown below: Open the OpenShift console to view the artificats created as part of this exerice. Guestbook operator pod: Guestbook application pods:","title":"5. Deploy the operand by applying the custom resource (CR) into the cluster."},{"location":"lab3/#6-cleanup-the-deployment","text":"Remove the Guestbook application by deleting the customer resource (CR). oc delete -f config/samples/charts_v1alpha1_guestbook.yaml $ oc delete -f config/samples/charts_v1alpha1_guestbook.yaml guestbook.charts.guestbook.ibm.com \"guestbook-sample\" deleted $ oc get all -n guestbook No resources found in guestbook namespace. $ oc delete project guestbook project.project.openshift.io \"guestbook\" deleted Finally, to delete the CRDs, run the make undeploy command: make undeploy $ make undeploy /home/student/guestbook-operator-project/bin/kustomize build config/default | kubectl delete -f - namespace \"gb-helm-operator-system\" deleted customresourcedefinition.apiextensions.k8s.io \"guestbooks.charts.guestbook.ibm.com\" deleted role.rbac.authorization.k8s.io \"gb-helm-operator-leader-election-role\" deleted clusterrole.rbac.authorization.k8s.io \"gb-helm-operator-manager-role\" deleted clusterrole.rbac.authorization.k8s.io \"gb-helm-operator-metrics-reader\" deleted clusterrole.rbac.authorization.k8s.io \"gb-helm-operator-proxy-role\" deleted rolebinding.rbac.authorization.k8s.io \"gb-helm-operator-leader-election-rolebinding\" deleted clusterrolebinding.rbac.authorization.k8s.io \"gb-helm-operator-manager-rolebinding\" deleted clusterrolebinding.rbac.authorization.k8s.io \"gb-helm-operator-proxy-rolebinding\" deleted service \"gb-helm-operator-controller-manager-metrics-service\" deleted deployment.apps \"gb-helm-operator-controller-manager\" deleted This concludes the Helm Operator lab. Go here for additional information on building operators using Helm.","title":"6. Cleanup the deployment."},{"location":"lab4/","text":"Introduction to Operator Lifecyle Management \u00b6 COMING SOON! \u00b6","title":"Introduction"},{"location":"lab4/#introduction-to-operator-lifecyle-management","text":"","title":"Introduction to Operator Lifecyle Management"},{"location":"lab4/#coming-soon","text":"","title":"COMING SOON!"},{"location":"lab5/","text":"Building Operator with OLM \u00b6 COMING SOON! \u00b6","title":"Operator with OLM"},{"location":"lab5/#building-operator-with-olm","text":"","title":"Building Operator with OLM"},{"location":"lab5/#coming-soon","text":"","title":"COMING SOON!"},{"location":"lab6/","text":"Operator Tools \u00b6 To write applications that use the Kubernetes REST API, you can use one of the following supported client libraries: Go , Python , Java , CSharp dotnet , JavaScript , Haskell . In addition, there are many community-maintained client libraries . At the OperatorHub.io , you find ready to use operators written by the community. To write your own operator you can use existing tools: KUDO (Kubernetes Universal Declarative Operator), kubebuilder , Metacontroller using custom WebHooks, the Operator Framework .","title":"Tools"},{"location":"lab6/#operator-tools","text":"To write applications that use the Kubernetes REST API, you can use one of the following supported client libraries: Go , Python , Java , CSharp dotnet , JavaScript , Haskell . In addition, there are many community-maintained client libraries . At the OperatorHub.io , you find ready to use operators written by the community. To write your own operator you can use existing tools: KUDO (Kubernetes Universal Declarative Operator), kubebuilder , Metacontroller using custom WebHooks, the Operator Framework .","title":"Operator Tools"},{"location":"setup/","text":"Client Setup \u00b6 Access the web-terminal \u00b6 When running the lab for Kubernetes Extensions, you can make use of a web-terminal. The Dockerfile to use is located in https://github.com/IBMAppModernization/web-terminal , and named Dockerfile-s2i-oc-tekton-operator . To run on localhost as a Docker container, git clone https://github.com/IBMAppModernization/web-terminal.git cd web-terminal docker build --no-cache -t web-terminal:latest -f Dockerfile-s2i-oc-tekton-operator . docker run -d --restart always --name terminal -p 7681 :7681 -v $HOME /dev/tmp:/root/dev web-terminal docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 85edc0b0ec27 web-terminal \"ttyd -p 7681 bash\" 17 minutes ago Up 17 minutes 0 .0.0.0:7681->7681/tcp terminal The volume mapping will write all files under the working directory to the host directory $HOME/dev/tmp . So suppose my host's user home directory is /Users/remkohdev@us.ibm.com/ . If I open the terminal in the browser, the working directory for the user is /root . Any file that is created under /root is created on the host's directory $HOME/dev/tmp . Similarly if I create a file in $HOME/dev/tmp it is available in the container's /root directory. Open the web-terminal in a browser and go to http://0.0.0.0:7681 . If Go, Operator SD export CLUSTERNAME = remkohdev-roks-labs-3n-cluster ibmcloud login Go to the OpenShift web console Copy Login command oc login --token = _12AbcD345kIPDIRg2jYpCuZ-g5SM5Im9irY2tol4Q8 --server = https://c100-e.us-south.containers.cloud.ibm.com:30712","title":"Setup"},{"location":"setup/#client-setup","text":"","title":"Client Setup"},{"location":"setup/#access-the-web-terminal","text":"When running the lab for Kubernetes Extensions, you can make use of a web-terminal. The Dockerfile to use is located in https://github.com/IBMAppModernization/web-terminal , and named Dockerfile-s2i-oc-tekton-operator . To run on localhost as a Docker container, git clone https://github.com/IBMAppModernization/web-terminal.git cd web-terminal docker build --no-cache -t web-terminal:latest -f Dockerfile-s2i-oc-tekton-operator . docker run -d --restart always --name terminal -p 7681 :7681 -v $HOME /dev/tmp:/root/dev web-terminal docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 85edc0b0ec27 web-terminal \"ttyd -p 7681 bash\" 17 minutes ago Up 17 minutes 0 .0.0.0:7681->7681/tcp terminal The volume mapping will write all files under the working directory to the host directory $HOME/dev/tmp . So suppose my host's user home directory is /Users/remkohdev@us.ibm.com/ . If I open the terminal in the browser, the working directory for the user is /root . Any file that is created under /root is created on the host's directory $HOME/dev/tmp . Similarly if I create a file in $HOME/dev/tmp it is available in the container's /root directory. Open the web-terminal in a browser and go to http://0.0.0.0:7681 . If Go, Operator SD export CLUSTERNAME = remkohdev-roks-labs-3n-cluster ibmcloud login Go to the OpenShift web console Copy Login command oc login --token = _12AbcD345kIPDIRg2jYpCuZ-g5SM5Im9irY2tol4Q8 --server = https://c100-e.us-south.containers.cloud.ibm.com:30712","title":"Access the web-terminal"}]}